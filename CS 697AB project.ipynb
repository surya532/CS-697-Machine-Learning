{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 697AB project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_kjO0xQ94nV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLsg6FstSD_6"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDrqlCAu99fG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bef35a-bc1b-453c-9d05-59a1ab0051a7"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WTuWISNSDLf"
      },
      "source": [
        "# Split Train dataset into Train + Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xq_2cCWQ6Tl"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,\n",
        "                                                      test_size=5000)\n",
        "\n",
        "\n",
        "# Normalization\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid /255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2OsaZtMZIzg"
      },
      "source": [
        "# Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY4e-x2V-o8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9f9246-283e-44cd-8fcf-77238009be7c"
      },
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(30, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(40, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "concat = keras.layers.Concatenate()([input, bat2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.4)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 28, 30)       870         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 30)       120         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 28, 40)       1240        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 40)       160         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 28, 68)       0           input_1[0][0]                    \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1904)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1904)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           19050       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,440\n",
            "Trainable params: 21,300\n",
            "Non-trainable params: 140\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJ4hKCy-ypc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6da4373-846c-4cfd-f7a3-a4b10ccfcc5e"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5271 - accuracy: 0.8158 - val_loss: 0.3702 - val_accuracy: 0.8674\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4113 - accuracy: 0.8539 - val_loss: 0.3476 - val_accuracy: 0.8708\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3864 - accuracy: 0.8623 - val_loss: 0.3318 - val_accuracy: 0.8774\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3693 - accuracy: 0.8669 - val_loss: 0.3245 - val_accuracy: 0.8838\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3540 - accuracy: 0.8725 - val_loss: 0.3352 - val_accuracy: 0.8790\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3481 - accuracy: 0.8745 - val_loss: 0.3315 - val_accuracy: 0.8806\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3421 - accuracy: 0.8755 - val_loss: 0.3206 - val_accuracy: 0.8902\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3326 - accuracy: 0.8804 - val_loss: 0.3136 - val_accuracy: 0.8918\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3291 - accuracy: 0.8796 - val_loss: 0.3063 - val_accuracy: 0.8890\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3253 - accuracy: 0.8815 - val_loss: 0.3157 - val_accuracy: 0.8858\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3218 - accuracy: 0.8816 - val_loss: 0.3095 - val_accuracy: 0.8920\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3167 - accuracy: 0.8853 - val_loss: 0.3105 - val_accuracy: 0.8912\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3170 - accuracy: 0.8835 - val_loss: 0.3512 - val_accuracy: 0.8710\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3138 - accuracy: 0.8854 - val_loss: 0.3043 - val_accuracy: 0.8932\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3120 - accuracy: 0.8864 - val_loss: 0.3114 - val_accuracy: 0.8926\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3096 - accuracy: 0.8873 - val_loss: 0.3191 - val_accuracy: 0.8850\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3048 - accuracy: 0.8891 - val_loss: 0.3070 - val_accuracy: 0.8910\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3022 - accuracy: 0.8895 - val_loss: 0.2995 - val_accuracy: 0.8934\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3042 - accuracy: 0.8885 - val_loss: 0.3011 - val_accuracy: 0.8950\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3025 - accuracy: 0.8890 - val_loss: 0.2918 - val_accuracy: 0.8968\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2996 - accuracy: 0.8891 - val_loss: 0.3098 - val_accuracy: 0.8910\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2982 - accuracy: 0.8907 - val_loss: 0.3140 - val_accuracy: 0.8928\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2964 - accuracy: 0.8913 - val_loss: 0.3061 - val_accuracy: 0.8902\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2962 - accuracy: 0.8923 - val_loss: 0.3208 - val_accuracy: 0.8828\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2932 - accuracy: 0.8919 - val_loss: 0.3027 - val_accuracy: 0.8944\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2941 - accuracy: 0.8923 - val_loss: 0.3077 - val_accuracy: 0.8902\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2920 - accuracy: 0.8927 - val_loss: 0.3004 - val_accuracy: 0.8924\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2918 - accuracy: 0.8919 - val_loss: 0.3192 - val_accuracy: 0.8914\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2888 - accuracy: 0.8930 - val_loss: 0.3124 - val_accuracy: 0.8884\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2888 - accuracy: 0.8946 - val_loss: 0.2886 - val_accuracy: 0.8952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAmeSb8WBOS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa049b02-104b-421b-fdc6-3d5a42b2d2c5"
      },
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Acc:  89.46181535720825\n",
            "Validation Acc:  89.52000141143799\n",
            "Test Acc:  88.84000182151794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCzr1Z71B1Dg"
      },
      "source": [
        "# Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovE6P_TLB0qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6da075b-fb50-4005-8084-09572c8df4f4"
      },
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(55, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(75, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "concat = keras.layers.Concatenate()([input, bat2])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.5)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 28, 55)       1595        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 55)       220         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 28, 75)       4200        batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 75)       300         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 28, 103)      0           input_2[0][0]                    \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2884)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2884)         0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           28850       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 35,165\n",
            "Trainable params: 34,905\n",
            "Non-trainable params: 260\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSxtqlhxC12i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25276dd-3e26-4234-d846-2f2e74aad410"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5669 - accuracy: 0.8162 - val_loss: 0.4168 - val_accuracy: 0.8576\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4264 - accuracy: 0.8541 - val_loss: 0.3516 - val_accuracy: 0.8734\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3894 - accuracy: 0.8624 - val_loss: 0.3276 - val_accuracy: 0.8808\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3696 - accuracy: 0.8679 - val_loss: 0.3793 - val_accuracy: 0.8556\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3518 - accuracy: 0.8744 - val_loss: 0.3308 - val_accuracy: 0.8818\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3414 - accuracy: 0.8764 - val_loss: 0.3131 - val_accuracy: 0.8850\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3288 - accuracy: 0.8817 - val_loss: 0.3007 - val_accuracy: 0.8908\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3253 - accuracy: 0.8839 - val_loss: 0.3177 - val_accuracy: 0.8930\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3185 - accuracy: 0.8858 - val_loss: 0.2994 - val_accuracy: 0.8946\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3117 - accuracy: 0.8872 - val_loss: 0.2980 - val_accuracy: 0.8954\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3077 - accuracy: 0.8888 - val_loss: 0.2949 - val_accuracy: 0.8938\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3057 - accuracy: 0.8889 - val_loss: 0.2979 - val_accuracy: 0.8966\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3024 - accuracy: 0.8887 - val_loss: 0.3031 - val_accuracy: 0.8916\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2963 - accuracy: 0.8928 - val_loss: 0.2988 - val_accuracy: 0.8932\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2969 - accuracy: 0.8922 - val_loss: 0.2971 - val_accuracy: 0.8934\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2901 - accuracy: 0.8949 - val_loss: 0.2962 - val_accuracy: 0.8972\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2891 - accuracy: 0.8947 - val_loss: 0.2974 - val_accuracy: 0.8966\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2866 - accuracy: 0.8956 - val_loss: 0.3080 - val_accuracy: 0.8946\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2850 - accuracy: 0.8962 - val_loss: 0.2937 - val_accuracy: 0.8950\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2831 - accuracy: 0.8955 - val_loss: 0.2849 - val_accuracy: 0.9002\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2821 - accuracy: 0.8971 - val_loss: 0.2856 - val_accuracy: 0.8988\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2743 - accuracy: 0.9006 - val_loss: 0.2900 - val_accuracy: 0.8998\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2824 - accuracy: 0.8969 - val_loss: 0.2923 - val_accuracy: 0.8994\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2752 - accuracy: 0.8995 - val_loss: 0.2844 - val_accuracy: 0.9002\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2738 - accuracy: 0.8998 - val_loss: 0.2840 - val_accuracy: 0.8990\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2756 - accuracy: 0.8995 - val_loss: 0.3142 - val_accuracy: 0.8938\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2709 - accuracy: 0.9004 - val_loss: 0.2874 - val_accuracy: 0.8980\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2703 - accuracy: 0.9006 - val_loss: 0.2993 - val_accuracy: 0.8992\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2704 - accuracy: 0.9012 - val_loss: 0.3029 - val_accuracy: 0.8948\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2726 - accuracy: 0.8999 - val_loss: 0.2966 - val_accuracy: 0.8980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFQdhLVHC2mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a3de96-6b55-4924-ed7f-4b251e7341c2"
      },
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Acc:  89.99272584915161\n",
            "Validation Acc:  89.80000019073486\n",
            "Test Acc:  88.88999819755554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeIujOUoC8Z1"
      },
      "source": [
        "# Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW3OllAgC6IG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3160761a-6675-4a83-d31f-1c113382d8b0"
      },
      "source": [
        "input = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hid1 = keras.layers.Dense(100, activation='relu')(input)\n",
        "bat1 = keras.layers.BatchNormalization()(hid1)\n",
        "hid2 = keras.layers.Dense(250, activation='relu')(bat1)\n",
        "bat2 = keras.layers.BatchNormalization()(hid2)\n",
        "hid3 = keras.layers.Dense(500, activation='relu')(bat2)\n",
        "bat3 = keras.layers.BatchNormalization()(hid3)\n",
        "concat = keras.layers.Concatenate()([input, bat3])\n",
        "flatten = keras.layers.Flatten()(concat)\n",
        "dropout = keras.layers.Dropout(0.5)(flatten)\n",
        "output = keras.layers.Dense(10, activation='softmax')(dropout)\n",
        "model = keras.models.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 28, 100)      2900        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 100)      400         dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 28, 250)      25250       batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 250)      1000        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 28, 500)      125500      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 500)      2000        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 528)      0           input_3[0][0]                    \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 14784)        0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 14784)        0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           147850      dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 304,900\n",
            "Trainable params: 303,200\n",
            "Non-trainable params: 1,700\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpZ1CiD5DSvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d76951e-f3e9-48e3-8622-c4054510a880"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9495 - accuracy: 0.8083 - val_loss: 0.5533 - val_accuracy: 0.8504\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6193 - accuracy: 0.8405 - val_loss: 0.4353 - val_accuracy: 0.8700\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5394 - accuracy: 0.8550 - val_loss: 0.4211 - val_accuracy: 0.8704\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4744 - accuracy: 0.8660 - val_loss: 0.3747 - val_accuracy: 0.8846\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4213 - accuracy: 0.8741 - val_loss: 0.3562 - val_accuracy: 0.8854\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4027 - accuracy: 0.8784 - val_loss: 0.3522 - val_accuracy: 0.8902\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3699 - accuracy: 0.8805 - val_loss: 0.3493 - val_accuracy: 0.8898\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3381 - accuracy: 0.8890 - val_loss: 0.3449 - val_accuracy: 0.8904\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3196 - accuracy: 0.8915 - val_loss: 0.3080 - val_accuracy: 0.8924\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3164 - accuracy: 0.8938 - val_loss: 0.3266 - val_accuracy: 0.8892\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2907 - accuracy: 0.8997 - val_loss: 0.3028 - val_accuracy: 0.8958\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2731 - accuracy: 0.9037 - val_loss: 0.3046 - val_accuracy: 0.9002\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2657 - accuracy: 0.9067 - val_loss: 0.3212 - val_accuracy: 0.8942\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2544 - accuracy: 0.9103 - val_loss: 0.3255 - val_accuracy: 0.8904\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2527 - accuracy: 0.9090 - val_loss: 0.3009 - val_accuracy: 0.9048\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2348 - accuracy: 0.9143 - val_loss: 0.3169 - val_accuracy: 0.9002\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2235 - accuracy: 0.9197 - val_loss: 0.3465 - val_accuracy: 0.8864\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2239 - accuracy: 0.9197 - val_loss: 0.3223 - val_accuracy: 0.8954\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2191 - accuracy: 0.9210 - val_loss: 0.3187 - val_accuracy: 0.8950\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2078 - accuracy: 0.9249 - val_loss: 0.3542 - val_accuracy: 0.8896\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2035 - accuracy: 0.9286 - val_loss: 0.3214 - val_accuracy: 0.8994\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2031 - accuracy: 0.9279 - val_loss: 0.3334 - val_accuracy: 0.8958\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.1945 - accuracy: 0.9301 - val_loss: 0.3322 - val_accuracy: 0.9020\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1931 - accuracy: 0.9315 - val_loss: 0.3390 - val_accuracy: 0.8976\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1874 - accuracy: 0.9330 - val_loss: 0.3430 - val_accuracy: 0.9002\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1816 - accuracy: 0.9352 - val_loss: 0.3561 - val_accuracy: 0.8972\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1772 - accuracy: 0.9364 - val_loss: 0.3591 - val_accuracy: 0.8998\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1752 - accuracy: 0.9377 - val_loss: 0.3366 - val_accuracy: 0.9034\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1744 - accuracy: 0.9380 - val_loss: 0.3595 - val_accuracy: 0.9014\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1662 - accuracy: 0.9409 - val_loss: 0.4044 - val_accuracy: 0.8990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hbssgXtDU2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2026f394-1c7b-41b5-e1da-14261f9cd00f"
      },
      "source": [
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Train Acc: \", history.history['accuracy'][-1] * 100)\n",
        "print(\"Validation Acc: \", history.history['val_accuracy'][-1] * 100)\n",
        "print(\"Test Acc: \", test_acc * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Acc:  94.09454464912415\n",
            "Validation Acc:  89.89999890327454\n",
            "Test Acc:  89.24000263214111\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}